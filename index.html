<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dreamlike Christmas Tree - Gesture Interactive</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #050505; /* Deep dark background, not pure black */
            font-family: 'Courier New', Courier, monospace;
        }
        
        #canvas-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
        }

        /* Overlay for initial interaction (Audio Context requirement) */
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.85);
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            color: #ff6fae;
            z-index: 10;
            transition: opacity 1s ease;
            cursor: pointer;
            text-align: center;
            padding: 20px;
        }

        #overlay h1 {
            font-weight: 300;
            text-shadow: 0 0 10px #ff6fae;
            letter-spacing: 2px;
        }

        #overlay p {
            color: #fff;
            max-width: 600px;
            line-height: 1.6;
        }

        #overlay .start-notes {
            font-size: 12px;
            color: rgba(255,255,255,0.85);
            opacity: 0.95;
            margin-top: 10px;
            max-width: 600px;
            line-height: 1.4;
        }

        .hidden {
            display: none !important;
            opacity: 0;
            pointer-events: none;
        }

        /* Hidden inputs/media */
        #user-audio-input { display: none; }
        #bg-music { display: none; }
        #video-source { display: none; }

        /* Loading indicator */
        #loading {
            position: absolute;
            bottom: 20px;
            left: 20px;
            color: rgba(255, 255, 255, 0.5);
            font-size: 12px;
            z-index: 5;
        }
        
        /* Mirror the video element for debugging if needed, but we hide it */
        .input_video {
            display: none; 
        }
    </style>
</head>
<body>

    <div id="canvas-container"></div>

    <div id="overlay">
        <h1>Merry Christmas</h1>
        <p>
            Allow camera access.<br>
            å…è®¸è®¿é—®æ‘„åƒå¤´ã€‚<br>
            <b>Open Palm:</b> Scatter Stars<br>
            <b>å¼ å¼€æ‰‹æŒï¼š</b> æ’’æ’­æ˜Ÿæ˜Ÿ<br>
            <b>Closed Palm:</b> Assemble Tree<br>
            <b>åˆæ‹¢æ‰‹æŒï¼š</b> ç»„è£…åœ£è¯æ ‘<br>
            <b>Pinch (Thumb+Index):</b> Play Memory<br>
            <b>æï¼ˆæ‹‡æŒ‡+é£ŸæŒ‡ï¼‰ï¼š</b> æ’­æ”¾è®°å¿†<br>
            <b>Move Hand:</b> Rotate<br>
            <b>ç§»åŠ¨æ‰‹éƒ¨ï¼š</b> æ—‹è½¬<br><br>
            [ Click anywhere to Begin ]<br>
            [ ç‚¹å‡»ä»»æ„ä½ç½®å¼€å§‹ ]
        </p>
        <p class="start-notes">æ‘„åƒå¤´å¯èƒ½éœ€è¦ç¼“å†²ä¸€æ®µæ—¶é—´æ‰èƒ½ä½¿ç”¨æ‰‹åŠ¿<br>ç²’å­æ•£å¼€åè§†é¢‘å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´æ‰èƒ½åŠ è½½å‡ºæ¥</p>
    </div>

    <script>
        // Fallback inline click handler: ensures the overlay responds immediately
        // and notifies the module (dispatches a `user-start` event) when clicked.
        window.__userClickedStart = false;
        (function(){
            const overlayEl = document.getElementById('overlay');
            if (!overlayEl) return;
            overlayEl.addEventListener('click', async () => {
                // quick visual feedback
                overlayEl.style.opacity = '0';
                setTimeout(() => { overlayEl.style.display = 'none'; }, 500);
                window.__userClickedStart = true;

                // Create/resume AudioContext synchronously from the user gesture
                try{
                    const AC = window.AudioContext || window.webkitAudioContext;
                    if (AC) window.__ac = window.__ac || new AC();
                }catch(e){ /* ignore */ }

                // Bundle audio playback and camera request in the same click handler
                // so mobile browsers treat both as coming from the same user gesture.
                try{
                    const bg = document.getElementById('bg-music');

                    // Synchronously start audio playback in this user gesture.
                    try{
                        if (bg){ bg.muted = false; bg.play().catch(()=>{}); }
                        const AC = window.AudioContext || window.webkitAudioContext;
                        if (AC){ window.__ac = window.__ac || new AC(); window.__ac.resume().catch(()=>{}); }
                    }catch(e){ /* ignore */ }

                    // Prefer the robust `requestCameraStream` helper (polyfilled below)
                    // which wraps legacy getUserMedia and provides a file-capture fallback
                    // Attempt camera with retries on AbortError (some platforms abort
                    // the request when the permission prompt is shown). This wrapper
                    // will retry a couple times before giving up.
                    const attemptCamera = async (constraints, retries = 2) => {
                        constraints = constraints || { video: { facingMode: 'user' }, audio: false };
                        for (let i = 0; i <= retries; i++){
                            try{
                                if (window.requestCameraStream) return await window.requestCameraStream(constraints);
                                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) return await navigator.mediaDevices.getUserMedia(constraints);
                                throw new Error('getUserMedia not supported');
                            }catch(err){
                                // If aborted by browser while showing permission prompt, retry a few times
                                if ((err && err.name === 'AbortError') && i < retries){
                                    console.warn('getUserMedia aborted, retrying...', i+1);
                                    await new Promise(r => setTimeout(r, 300 + i*200));
                                    continue;
                                }
                                throw err;
                            }
                        }
                    };
                    const cameraPromise = attemptCamera({ video: { facingMode: 'user' }, audio: false }, 2);

                    const [camResult] = await Promise.allSettled([cameraPromise]);

                    if (camResult && camResult.status === 'fulfilled'){
                        const result = camResult.value;
                        let camVideo = document.querySelector('.input_video');

                        // If the helper returned a MediaStream, attach it directly.
                        if (result && result instanceof MediaStream){
                            if (!camVideo){
                                camVideo = document.createElement('video');
                                camVideo.className = 'input_video';
                                camVideo.style.display = 'none';
                                document.body.appendChild(camVideo);
                            }
                            camVideo.playsInline = true;
                            camVideo.muted = true;
                            try{ camVideo.srcObject = result; }catch(e){ console.warn('srcObject attach failed', e); }
                            // Try to start playback immediately; many browsers will begin rendering
                            // frames faster if `play()` is awaited and the element is configured.
                            // Also attach a loadedmetadata/playing listener to resume audio/context
                            const resumeAudioAfterCamera = async () => {
                                try{
                                    const AC = window.AudioContext || window.webkitAudioContext;
                                    if (AC){ window.__ac = window.__ac || new AC(); await window.__ac.resume().catch(()=>{}); }
                                    if (bg && bg.paused){ await bg.play().catch(()=>{}); }
                                }catch(e){ console.warn('Failed to resume audio after camera metadata', e); }
                            };
                            camVideo.addEventListener('loadedmetadata', async ()=>{
                                await resumeAudioAfterCamera();
                                document.dispatchEvent(new Event('camera-ready'));
                            }, { once:true });
                            camVideo.addEventListener('playing', async ()=>{
                                await resumeAudioAfterCamera();
                                document.dispatchEvent(new Event('camera-ready'));
                            }, { once:true });
                            camVideo.play().catch(()=>{ /* ignore play promise rejection */ });

                        // If the fallback returned a video element (file fallback), use it.
                        }else if (result && result.videoElement){
                            // Remove existing camVideo and insert the provided one so downstream
                            // listeners/readers see the active element.
                            if (camVideo && camVideo.parentNode) camVideo.parentNode.removeChild(camVideo);
                            const provided = result.videoElement;
                            provided.classList.add('input_video');
                            provided.style.display = 'none';
                            document.body.appendChild(provided);
                            // Attach resume listener to the provided fallback video too
                            const resumeAudioFallback = async ()=>{
                                try{
                                    const AC = window.AudioContext || window.webkitAudioContext;
                                    if (AC){ window.__ac = window.__ac || new AC(); await window.__ac.resume().catch(()=>{}); }
                                    if (bg && bg.paused){ await bg.play().catch(()=>{}); }
                                }catch(e){ console.warn('Failed to resume audio for fallback video', e); }
                            };
                            provided.addEventListener('loadedmetadata', async ()=>{ await resumeAudioFallback(); document.dispatchEvent(new Event('camera-ready')); }, { once:true });
                            provided.addEventListener('playing', async ()=>{ await resumeAudioFallback(); document.dispatchEvent(new Event('camera-ready')); }, { once:true });
                            provided.play().catch(()=>{});
                        }else{
                            console.warn('Camera result is not a MediaStream or fallback video', result);
                            document.dispatchEvent(new Event('camera-ready'));
                        }
                    } else {
                        console.warn('Camera request failed or was denied', camResult && camResult.reason);
                        document.dispatchEvent(new Event('camera-ready'));
                    }
                }catch(e){ console.warn('Start handler error', e); }

                document.dispatchEvent(new Event('user-start'));
                console.log('Overlay clicked (start handler)');
            });
        })();
    </script>

    <!-- Start muted to allow mobile/autoplay policies to accept playback; will unmute on user gesture -->
    <audio id="bg-music" loop preload="auto" muted crossorigin="anonymous">
        <source src="Last Christmas.bgm.mp3" type="audio/mpeg">
        Your browser does not support the audio element.
    </audio>

    <script>
        // Attempt muted playback to satisfy mobile autoplay policies, then unmute on user gesture.
        (function(){
            const bg = document.getElementById('bg-music');
            const vid = document.getElementById('video-source');
            function tryMutedPlay(){
                try{
                    if (vid){ vid.muted = true; vid.playsInline = true; vid.play().catch(()=>{}); }
                    if (bg){ bg.muted = true; bg.play().catch(()=>{}); }
                }catch(e){}
            }

            // Try immediately and on first pointer/touch (some browsers allow gesture from touchstart)
            tryMutedPlay();
            window.addEventListener('pointerdown', tryMutedPlay, { once: true });
            window.addEventListener('touchstart', tryMutedPlay, { once: true });

            // On the explicit user-start (overlay click) try to resume audio and unmute
            document.addEventListener('user-start', async ()=>{
                try{
                    const AC = window.AudioContext || window.webkitAudioContext;
                    if (AC){ window.__ac = window.__ac || new AC(); await window.__ac.resume().catch(()=>{}); }
                    if (bg){ bg.muted = false; await bg.play().catch(()=>{}); }
                    if (vid){ vid.muted = false; await vid.play().catch(()=>{}); }
                }catch(e){ console.warn('user-start playback resume failed', e); }
            }, { once:true });

            // Emit a 'video-ready' event when the video can be used as a texture
            if (vid){
                const fire = ()=> document.dispatchEvent(new Event('video-ready'));
                vid.addEventListener('canplay', fire, { once:true });
                vid.addEventListener('canplaythrough', fire, { once:true });
                if (vid.readyState >= 3) fire();
            }

            // Resume background audio when camera permission is granted and the
            // camera input video starts playing. Also dispatch a `camera-ready`
            // event which the main hand-tracking code can listen to to begin
            // processing as soon as frames are available.
            (function(){
                const resumeAfterCamera = async () => {
                    try{
                        const bgEl = document.getElementById('bg-music');
                        const AC = window.AudioContext || window.webkitAudioContext;
                        if (AC){ window.__ac = window.__ac || new AC(); await window.__ac.resume().catch(()=>{}); }
                        if (bgEl && bgEl.paused){ await bgEl.play().catch(()=>{}); }
                    }catch(e){ console.warn('Resuming audio after camera grant failed', e); }
                };

                // Listen for the custom camera-ready event fired after stream attach/play
                document.addEventListener('camera-ready', ()=>{
                    resumeAfterCamera();
                }, { once:true });

                // Also attach to any .input_video element events in case it's already present
                const camVideo = document.querySelector('.input_video');
                if (camVideo){
                    const onceReady = ()=> document.dispatchEvent(new Event('camera-ready'));
                    camVideo.addEventListener('loadeddata', onceReady, { once:true });
                    camVideo.addEventListener('canplay', onceReady, { once:true });
                    camVideo.addEventListener('playing', onceReady, { once:true });
                }
            })();
        })();
    </script>

    <video id="video-source" loop playsinline crossOrigin="anonymous" style="display:none">
        <source src="bg_video.mp4" type="video/mp4">
    </video>

    <input type="file" id="user-audio-input" accept="audio/mpeg, audio/mp3, audio/ogg">

    <video class="input_video"></video>

    <div id="loading">Initializing Neural Net & Graphics...</div>

    <div id="audio-controls" style="position:fixed; right:20px; bottom:20px; z-index:20; color:#fff; font-size:13px; display:flex; gap:8px; align-items:center;">
        <button id="audio-toggle">Play</button>
        <button id="audio-choose">Choose BGM...</button>
        <span id="audio-status" style="opacity:0.85; font-size:12px; max-width:220px; display:inline-block; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"></span>
    </div>

    <script>
        // Visible controls + file-picker hookup + error messages
        (function(){
            const bg = document.getElementById('bg-music');
            const toggle = document.getElementById('audio-toggle');
            const choose = document.getElementById('audio-choose');
            const input = document.getElementById('user-audio-input');
            const status = document.getElementById('audio-status');
            if (!bg || !toggle || !choose || !input || !status) return;

            function updateStatus(){
                const src = bg.currentSrc || bg.src || '';
                const playState = bg.paused ? 'Paused' : 'Playing';
                status.textContent = src ? `${playState} â€” ${src.split('/').pop()}` : 'No audio file selected';
                toggle.textContent = bg.paused ? 'Play' : 'Pause Music';
            }

            toggle.addEventListener('click', async ()=>{
                try{
                    if (bg.paused) await bg.play(); else bg.pause();
                }catch(e){
                    console.warn('Playback blocked or failed', e);
                    alert('Playback blocked. Click the page or choose a local file.');
                }
                updateStatus();
            });

            choose.addEventListener('click', ()=> input.click());

            input.addEventListener('change', (e)=>{
                const f = e.target.files && e.target.files[0];
                if (!f) return;
                const url = URL.createObjectURL(f);
                bg.src = url;
                bg.load();
                bg.play().catch(()=>{});
                updateStatus();
            });

            bg.addEventListener('error', ()=>{
                status.textContent = 'Error loading bgm.mp3 â€” place bgm.mp3 in the project root or choose one.';
                console.error('bgm load error', bg.error);
            });

            document.addEventListener('user-start', ()=>{
                bg.play().catch(()=>{});
                updateStatus();
            }, { once:true });

            // Initial status
            updateStatus();
        })();
    </script>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>

    <script>
        // Compatibility helper for legacy mobile webviews and older browsers.
        (function(){
            // WebGL context helper: try webgl2, webgl, experimental-webgl
            window.getWebGLContext = function(canvas, opts){
                if (!canvas) return null;
                const names = ['webgl2','webgl','experimental-webgl'];
                for (let i=0;i<names.length;i++){
                    try{
                        const ctx = canvas.getContext(names[i], opts);
                        if (ctx) return ctx;
                    }catch(e){}
                }
                return null;
            };

            // Polyfill navigator.mediaDevices.getUserMedia for older prefixed APIs
            if (typeof navigator !== 'undefined'){
                if (!navigator.mediaDevices) navigator.mediaDevices = {};
                if (!navigator.mediaDevices.getUserMedia){
                    const getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.getUserMedia;
                    if (getUserMedia){
                        navigator.mediaDevices.getUserMedia = function(constraints){
                            return new Promise(function(resolve, reject){
                                getUserMedia.call(navigator, constraints, resolve, reject);
                            });
                        };
                    }
                }
            }

            // Unified camera request helper with fallbacks for webview shells
            window.requestCameraStream = async function(constraints){
                constraints = constraints || { video: { facingMode: 'user' }, audio: false };
                try{
                    return await navigator.mediaDevices.getUserMedia(constraints);
                }catch(err){
                    // Retry with relaxed constraints
                    try{ return await navigator.mediaDevices.getUserMedia({ video: true, audio: false }); }catch(_){ }

                    // Fallback: use file input with capture attribute (works in many embedded shells)
                    return new Promise((resolve, reject)=>{
                        let input = document.getElementById('__camera_file_fallback');
                        if (!input){
                            input = document.createElement('input');
                            input.type = 'file';
                            input.accept = 'video/*,image/*';
                            input.capture = 'environment';
                            input.id = '__camera_file_fallback';
                            input.style.display = 'none';
                            document.body.appendChild(input);
                        }
                        input.onchange = function(e){
                            const file = input.files && input.files[0];
                            if (!file) return reject(new Error('No file selected'));
                            const videoEl = document.createElement('video');
                            videoEl.muted = true;
                            videoEl.playsInline = true;
                            videoEl.src = URL.createObjectURL(file);
                            videoEl.addEventListener('loadedmetadata', function(){
                                // Resolve with an object that mimics a MediaStream consumer
                                resolve({ fallbackFile: file, videoElement: videoEl });
                            }, { once:true });
                            videoEl.addEventListener('error', function(){ reject(new Error('Failed to load selected file')); }, { once:true });
                            videoEl.load();
                        };
                        input.click();
                    });
                }
            };

            // Detect embedded webviews (WeChat/QQ) and set a body class for optional styling
            try{
                const ua = navigator.userAgent || '';
                if (/MicroMessenger|QQ\//i.test(ua)) document.body.classList.add('embedded-webview');
            }catch(e){}

            // Show a minimal message when WebGL is not available
            function checkWebGLSupport(){
                const canvas = document.createElement('canvas');
                const gl = window.getWebGLContext(canvas);
                    if (!gl){
                    const el = document.createElement('div');
                    el.style.position = 'fixed'; el.style.left = '0'; el.style.right = '0'; el.style.top = '0'; el.style.bottom = '0';
                    el.style.zIndex = '99999';
                    el.style.display = 'flex'; el.style.alignItems = 'center'; el.style.justifyContent = 'center';

                    el.innerHTML = `
                        <style>
                            #webgl-christmas-overlay{position:fixed;inset:0;background:linear-gradient(180deg,#050505 0%, #111 60%);display:flex;align-items:center;justify-content:center;padding:20px;}
                            #webgl-christmas-card{max-width:720px;width:100%;background:linear-gradient(135deg,#0b2a16 0%, #123b1f 100%);border-radius:12px;padding:24px;color:#fff;box-shadow:0 8px 30px rgba(0,0,0,0.6);border:1px solid rgba(255,255,255,0.04);font-family:Courier,monospace}
                            #webgl-christmas-card h2{margin:0 0 8px;color:#ffd6e8;text-shadow:0 2px 8px rgba(255,111,174,0.08)}
                            #webgl-christmas-card p{opacity:0.95;margin:8px 0 14px;line-height:1.5}
                            .webgl-actions{display:flex;gap:10px;justify-content:center;margin-top:14px}
                            .webgl-btn{background:linear-gradient(180deg,#ff6fae,#ff4f9a);border:none;padding:10px 14px;border-radius:8px;color:#111;font-weight:700;cursor:pointer;box-shadow:0 6px 18px rgba(255,111,174,0.18)}
                            .webgl-ghost{background:transparent;border:1px solid rgba(255,255,255,0.12);color:#fff;padding:10px 14px;border-radius:8px;cursor:pointer}
                            .webgl-tips{display:flex;gap:12px;flex-wrap:wrap;justify-content:center;margin-top:12px;opacity:0.95}
                            .webgl-tip{background:rgba(255,255,255,0.04);padding:8px 10px;border-radius:8px;font-size:13px}
                            .santa-emoji{font-size:28px;margin-right:8px}
                        </style>
                        <div id="webgl-christmas-overlay">
                            <div id="webgl-christmas-card">
                                <div style="display:flex;align-items:center;justify-content:center;margin-bottom:8px">
                                    <div class="santa-emoji">ğŸ„</div>
                                    <h2>WebGL Not Available</h2>
                                </div>
                                <p>Ho ho â€” your browser doesn\'t appear to support WebGL or the required graphics features for this experience. For the best results open this page in your device\'s system browser (Safari / Chrome) or update your webview shell.</p>
                                <div class="webgl-tips">
                                    <div class="webgl-tip">Open in <strong>Safari</strong> for best iOS performance</div>
                                    <div class="webgl-tip">Use <strong>Chrome</strong> on Android</div>
                                    <div class="webgl-tip">Disable low-power / data-saving modes</div>
                                </div>
                                <div class="webgl-actions">
                                    <button class="webgl-btn webgl-retry">Retry</button>
                                    <button class="webgl-ghost webgl-close">Close</button>
                                </div>
                            </div>
                        </div>
                    `;
                    document.body.appendChild(el);

                    // Wire up buttons
                    setTimeout(()=>{
                        const retry = document.querySelector('.webgl-retry');
                        const close = document.querySelector('.webgl-close');
                        if (retry) retry.addEventListener('click', ()=> location.reload());
                        if (close) close.addEventListener('click', ()=> { el.remove(); });
                    }, 50);
                }
            }
            if (document.readyState === 'complete' || document.readyState === 'interactive') checkWebGLSupport(); else document.addEventListener('DOMContentLoaded', checkWebGLSupport);
        })();
    </script>

    <script type="module" src="./main.js"></script>
</body>
</html>